{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import BigramAssocMeasures\n",
    "from nltk.collocations import TrigramCollocationFinder, TrigramAssocMeasures\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install bertopic datasets accelerate bitsandbytes xformers adjustText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequency Analysis (Lufthansa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('combined_airline_review.csv')\n",
    "data_sub = data[data['Airline'].eq('Lufthansa')]\n",
    "data_sub = data_sub[data_sub['year']==2023]\n",
    "sub_reviews = data_sub['Review'].tolist()\n",
    "#data['Review'] = data['Review'].str.lower().replace('lufthansa', '', regex=False)\n",
    "#data['Review'] = data['Review'].str.lower().replace('british airway', '', regex=False)\n",
    "#data['Review'] = data['Review'].str.lower().replace('ba', '', regex=False)\n",
    "\n",
    "all_sentences = []\n",
    "for review in sub_reviews:\n",
    "    # use the sentence tokenizer\n",
    "    sentences = sent_tokenize(review)\n",
    "    # split each review into sentences and combine all sentences into a single list\n",
    "    # all_sentences contains each sentence from every review as a separate element\n",
    "    all_sentences.extend(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigram Word Frequency\n",
    "reviews = [sent.replace('\\xa0', '') for sent in all_sentences]\n",
    "reviews = [sent.replace('\\r\\n', '') for sent in reviews]\n",
    "reviews = [re.sub(\"\\'\", \"\", sent) for sent in reviews]\n",
    "reviews = [re.sub('\\W', ' ', sent) for sent in reviews]\n",
    "reviews = [sent.lower() for sent in reviews]\n",
    "# add airline's name into stopwrds\n",
    "stopword = stopwords.words(\"english\")+ ['lufthansa']\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "# split sentence into words\n",
    "word_tokens = [nltk.word_tokenize(sent) for sent in reviews]\n",
    "stemmed_word = [[snowball_stemmer.stem(word) for word in sent] for sent in word_tokens]\n",
    "c_text = [[word for word in sent if word not in stopword] for sent in stemmed_word]\n",
    "flat_words = [word for sent in c_text for word in sent]\n",
    "freq = FreqDist(flat_words)\n",
    "freq.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram Word Analysis\n",
    "\n",
    "# create a BigramCollocationFinder instance\n",
    "bigram_finder = BigramCollocationFinder.from_words(flat_words)\n",
    "# choose a measure to rank the bigrams: frequency\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "bigrams = bigram_finder.ngram_fd.items()\n",
    "bigramFreqTable = pd.DataFrame(list(bigrams), columns=['bigram','freq']).sort_values(by='freq', ascending=False)\n",
    "bigramFreqTable = bigramFreqTable.reset_index(drop=True)\n",
    "test_string = bigramFreqTable['bigram'].tolist()\n",
    "test_string[1][0] +'_' + test_string[1][1]\n",
    "#combine all tuples in df\n",
    "bigram = [ ]\n",
    "for c in range(0, len(test_string)):\n",
    "    bigram.append(test_string[c][0] +'_' + test_string[c][1])\n",
    "bigramFreqTable['bigram_combo'] = bigram\n",
    "# select the top20 to have a glance\n",
    "top20_bigram = bigramFreqTable[:20]\n",
    "plt.barh(top20_bigram['bigram_combo'], top20_bigram['freq']/len(data), color ='cyan', alpha = 0.4,\n",
    "         edgecolor = 'black', linewidth = 1)\n",
    "plt.xlabel(\"% of bigram that occurs together\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Frequency of Top 20 Bigrams\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the bigram result has more information than the unigram one. Like there are customer service, flight connection, flight delay...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Bigram\n",
    "bigram_freq_dict = pd.Series(bigramFreqTable.freq.values, index=bigramFreqTable.bigram_combo).to_dict()\n",
    "mask = np.array(Image.open(\"mask.png\"))\n",
    "wordcloud = WordCloud(background_color=\"white\", colormap='RdYlGn', mask = mask,).generate_from_frequencies(bigram_freq_dict)\n",
    "image_colors = ImageColorGenerator(mask)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Bigrams Word Cloud')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigram Analysis\n",
    "\n",
    "trigram_finder = TrigramCollocationFinder.from_words(flat_words)\n",
    "trigram_measures = TrigramAssocMeasures()\n",
    "trigrams = trigram_finder.ngram_fd.items()\n",
    "trigramFreqTable = pd.DataFrame(list(trigrams), columns=['trigram', 'freq']).sort_values(by='freq', ascending=False)\n",
    "trigramFreqTable = trigramFreqTable.reset_index(drop=True)\n",
    "trigram = []\n",
    "for c in range(0, len(trigramFreqTable)):\n",
    "    trigram.append(\"_\".join(trigramFreqTable['trigram'][c]))\n",
    "trigramFreqTable['trigram_combo'] = trigram\n",
    "top20_trigram = trigramFreqTable[:20]\n",
    "plt.barh(top20_trigram['trigram_combo'], top20_trigram['freq'] / len(data), color='cyan', alpha=0.4,\n",
    "         edgecolor='black', linewidth=1)\n",
    "plt.xlabel(\"% of trigram that occurs together\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Frequency of Top 20 Trigrams\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this is more informative, trigram turns less often to occur. So we don't choose this method. However, we can see 'small bottle water' should be the most concerned issue in food & beverage aspect. Other than this, flight delay and flight cancell bother a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling (Sentence Review Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import KMeans\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import bitsandbytes\n",
    "from torch import bfloat16\n",
    "import transformers\n",
    "\n",
    "\n",
    "# Pre-calculate embeddings\n",
    "embedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
    "embeddings = embedding_model.encode(all_sentences, show_progress_bar=True)\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\", ngram_range=(2,3)) # use bigram and trigram\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "cluster_model = KMeans(n_clusters=20)\n",
    "\n",
    "# Pre-reduce embeddings for visualization purposes\n",
    "reduced_embeddings = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=58).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 4-bit quantization\n",
    "    bnb_4bit_quant_type='nf4',  # Normalized float 4\n",
    "    bnb_4bit_use_double_quant=True,  # Second quantization after the first\n",
    "    bnb_4bit_compute_dtype=bfloat16  # Computation type\n",
    ")\n",
    "\n",
    "# Llama 2 Tokenizer\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Llama 2 Model\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our text generator\n",
    "generator = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    task='text-generation',\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=8000,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt describes information given to all conversations\n",
    "system_prompt = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful and honest assistant for finding issues from airline reviews.\n",
    "possible topics may include: seat comfort, cabin crew service, ground facilities, food and beverage, flight delay, groud customer service, wifi, inflight entertainment...\n",
    "<</SYS>>\n",
    "\"\"\"\n",
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt = \"\"\"\n",
    "I have a topic that contains the following documents which are airline customer reviews:\n",
    "- Worst customer service of all Airlines. I have never seen employees so rude that can't help resolve simple issues. Everytime there was an issue to arise they always say there is nothing they can do about it. I have booked with them twice and both times have been awful experiences.\n",
    "- Worst, the customer Service, cabin crew, specially main desk & boarding desk staffs at the airport are rude and unhelpful.\n",
    "- Customer service is really bad! Takes 40 to 45 minutes to talk to the agent. Incredibly hard to receive refund. No phone to contact a refund team. Not gonna use this airline again.\n",
    "\n",
    "The topic is described by the following keywords: 'customer service, Worst, cabin crew, rude, unhelpful, hard'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic about airline customer reviews. Make sure you to only return the label and nothing more.\n",
    "\n",
    "[/INST] Bad customer service with rude attitude.\n",
    "\"\"\"\n",
    "main_prompt = \"\"\"\n",
    "[INST]\n",
    "I have a topic that contains the following documents which are airline customer reviews:\n",
    "[DOCUMENTS]\n",
    "\n",
    "The topic is described by the following keywords: '[KEYWORDS]'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic about airline customer reviews. Make sure you to only return the label and nothing more.\n",
    "Do not just give a general label such as lufthansa flight experiences, but be more specific and give the positive sides or negative issues.\n",
    "[/INST]\n",
    "\"\"\"\n",
    "prompt = system_prompt + example_prompt + main_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, TextGeneration\n",
    "\n",
    "# KeyBERT\n",
    "keybert = KeyBERTInspired()\n",
    "\n",
    "# Text generation with Llama 2\n",
    "llama2 = TextGeneration(generator, prompt=prompt)\n",
    "\n",
    "# All representation models\n",
    "representation_model = {\n",
    "    \"KeyBERT\": keybert,\n",
    "    \"Llama2\": llama2,\n",
    "}\n",
    "\n",
    "topic_model = BERTopic(min_topic_size=4,\n",
    "                       language=\"english\",\n",
    "                       calculate_probabilities=True,\n",
    "                       verbose=True,\n",
    "                       umap_model=umap_model,\n",
    "                       hdbscan_model=cluster_model,\n",
    "                       representation_model=representation_model,\n",
    "                       embedding_model = 'multi-qa-mpnet-base-dot-v1',\n",
    "                       vectorizer_model=vectorizer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probs= topic_model.fit_transform(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = topic_model.get_topic_info()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "document_list = [\"Document \" + str(i) for i in range(1, (len(all_sentences)+1))]\n",
    "llama2_labels = [label[0][0].split(\"\\n\")[0] for label in topic_model.get_topics(full=True)[\"Llama2\"].values()]\n",
    "topic_model.set_topic_labels(llama2_labels)\n",
    "topic_model.visualize_documents(document_list, reduced_embeddings=reduced_embeddings, hide_annotations=True, hide_document_hover=False, custom_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize Llama2 Generator to give more detailed analysis on a review basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt describes information given to all conversations\n",
    "system_prompt = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "\n",
    "As a helpful text summary assistant, your tasks are:\n",
    "1. Tell which topics are related to this review. Pre-defined topics include: Seat Comfort, Cabin Staff Service, Food & Beverages, Inflight Entertainment, Ground Service,Wifi & Connectivity, Delay & Cancellation\n",
    "2. Generate the main labels related to each potential topic, don't too specific, also don't too general\n",
    "Your goal is to pinpoint the main negative issues or positive compliments highlighted in the reviews.\n",
    "<</SYS>>\n",
    "\"\"\"\n",
    "\n",
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt = \"\"\"\n",
    "I have an example that contains the following sentences:\n",
    "My experience with economy class seating comfort on the recent flight has been completely appalling. I have submitted my feedback to Lufthansa, and for this I have received a copy-pasted template response that have denied my request to compensation when I have not made or implied this request any at any point. \\\n",
    "Lufthansa made it clear that the comfort experience was as-intended by the company.\n",
    "\\The crux of the issue was lack of upper body ergonomics in the seats - while there was decent legroom provided, there was no way to rest my upper body without disturbing the passengers next to me, no matter how I tried to contort and what sitting poses I would pick.\n",
    "\\At its root, there is just not enough space between you and the forward seat ahead when it is reclined (which it will be on a long transatlantic flight!), the arm rests were useless, the angles between your body and seats/walls were uncomfortable, and the seating surface was just a bit too short.\n",
    "\\Additionally, the in-flight entertainment gets a low rating due to brightness issue compounded by lack of space - if the IFE screen is off, any time you try to move in your seat you will bump against it... at which point the screen comes back on at default brightness.\n",
    "\\This means it'll shine bright in your face and disturb people around you many-many times over on a dark flight.\n",
    "\\The default brightness is extremely bright for a dark flight condition when everyone is trying to sleep, and there seemed to be no way to make the IFE remember the brightness level.\n",
    "\\I did not use IFE for its intended entertainment purpose, so I cannot rate the media contents.\n",
    "\\The second short flight using A321neo was just OK.\n",
    "\\It provided the basic level of comfort, but was nothing to write home about.\n",
    "\\The other aspects of my flight were not notable in the context of just how very uncomfortable the seating was.one meal on a 10.30 hours long flight.\n",
    "\n",
    "The output should be:\n",
    "Seat Comfort:\n",
    "Negative Labels: Appalling, lack of upper body ergonomics, not enough space between seats, uncomfortable angles, short seating surface.\n",
    "Neutral Labels: Decent legroom, armrests were useless.\n",
    "Positive Labels: N/A.\n",
    "\n",
    "Cabin Staff Service:\n",
    "Negative Labels: Template response, denied compensation, company intention not to improve comfort.\n",
    "Neutral Labels: N/A.\n",
    "Positive Labels: N/Ad.\n",
    "\n",
    "Inflight Entertainment:\n",
    "Negative Labels: Brightness issue, lack of space, disturbance due to IFE screen, default brightness too bright, inability to adjust brightness.\n",
    "Neutral Labels: IFE screen off.\n",
    "Positive Labels: N/A.\n",
    "\n",
    "Food & Beverages:\n",
    "Negative Labels: Mention of only one meal on a long flight.\n",
    "Neutral Labels: N/A.\n",
    "Positive Labels: N/A.\n",
    "\n",
    "Ground Service:\n",
    "Negative Labels: N/A.\n",
    "Neutral Labels: N/A.\n",
    "Positive Labels: N/A.\n",
    "\n",
    "Wifi & Connectivity:\n",
    "Negative Labels: N/A.\n",
    "Neutral Labels: N/A.\n",
    "Positive Labels: N/A.\n",
    "\n",
    "Delay & Cancellation:\n",
    "Negative Labels: N/A.\n",
    "Neutral Labels: N/A.\n",
    "Positive Labels: N/A.\n",
    "\n",
    "Make sure only return related topics, negative labels, netural labels, positive labels, if there isn't related content, write N/A.\n",
    "\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "# Our main prompt with documents ([DOCUMENTS]) and keywords ([KEYWORDS]) tags\n",
    "main_prompt = \"\"\"\n",
    "[INST]\n",
    "I have this review:\n",
    "\n",
    "{text}\n",
    "\n",
    "Make sure return should be in following format, if there is no related content, write N/A. Make sure the labels are\\\n",
    "not too general, also not too specific, plz output a interpretable sentence:\n",
    "Seat Comfort:\n",
    "Negative Labels:\n",
    "Neutral Labels:\n",
    "Positive Labels:\n",
    "\n",
    "Cabin Staff Service:\n",
    "Negative Labels:\n",
    "Neutral Labels:\n",
    "Positive Labels:\n",
    "\n",
    "Inflight Entertainment:\n",
    "Negative Labels:\n",
    "Neutral Labels:\n",
    "Positive Labels:\n",
    "\n",
    "Food & Beverages:\n",
    "Negative Labels:\n",
    "Neutral Labels:\n",
    "Positive Labels:\n",
    "\n",
    "Ground Service:\n",
    "Negative Labels:\n",
    "Neutral Labels:\n",
    "Positive Labels:\n",
    "\n",
    "Wifi & Connectivity:\n",
    "Negative Labels:\n",
    "Neutral Labels:\n",
    "Positive Labels:\n",
    "\n",
    "Delay & Cancellation:\n",
    "Negative Labels:\n",
    "Neutral Labels:\n",
    "Positive Labels:\n",
    "\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    task='text-generation',\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=500,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False\n",
    ")\n",
    "review_test = data.Review[1]\n",
    "main_ = main_prompt.format(text=review_test)\n",
    "full_prompt = system_prompt +example_prompt + main_\n",
    "output = generator(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Review[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Seat Comfort:\n",
    "Negative Labels: None\n",
    "Neutral Labels: Small washroom\n",
    "Positive Labels: Good order & comfortable seats\n",
    "\n",
    "Cabin Staff Service:\n",
    "Negative Labels: None\n",
    "Neutral Labels: Friendly & professional\n",
    "Positive Labels: None\n",
    "\n",
    "Inflight Entertainment:\n",
    "Negative Labels: None\n",
    "Neutral Labels: IFE screen off\n",
    "Positive Labels: None\n",
    "\n",
    "Food & Beverages:\n",
    "Negative Labels: Limited menu options\n",
    "Neutral Labels: None\n",
    "Positive Labels: None\n",
    "\n",
    "Ground Service:\n",
    "Negative Labels: None\n",
    "Neutral Labels: None\n",
    "Positive Labels: Helpful ground staff member\n",
    "\n",
    "Wifi & Connectivity:\n",
    "Negative Labels: None\n",
    "Neutral Labels: None\n",
    "Positive Labels: None\n",
    "\n",
    "Delay & Cancellation:\n",
    "Negative Labels: Flight delay due to staffing issue at LHR\n",
    "Neutral Labels: Frequent updates from flight manager & flight deck\n",
    "Positive Labels: None\n",
    "\n",
    "Note: Since the reviewer mentioned only positive things about their flight experience, all labels are marked as \"Positive Labels\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this generator Llama2 can detailed split the positive and negative topics in a review, but it needs lots of computing resource. If user is particular interested in part pf reviews and would like to get a detailed analysis, this method works the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
